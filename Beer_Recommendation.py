# -*- coding: utf-8 -*-
"""HW 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16wBlBxQeOcCMS9bKHQio8Vbzurxd0N3C

#Text Analysis Homework 2: Recommending Beer
### Maryam Blooki
### Tairan Deng
### Daniel Stern
### Sunny Vidhani
###Justin Wagers
### Kaiwen Zhang

## Task A

Here we scrape 25 reviews for 250 beers for a total of 6,250 reviews from Beer Advocate's top rated beers list. We also scrape the numerical rating for each review.
"""

!pip install selenium
!apt-get -q update 
!apt install -yq chromium-chromedriver

import sys
import pandas as pd
sys.path.insert(0, '/user/lib/chromium-browser/chromedriver')
from selenium import webdriver
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome('chromedriver', options=chrome_options)

driver.get("https://www.beeradvocate.com/beer/top-rated/")
table_rows = driver.find_elements_by_xpath('/html/body/div[2]/div/div[2]/div[2]/div[2]/div/div/div[3]/div/div/div[2]/table/tbody/tr/td/a')
links = [row.get_attribute('href') for row in table_rows]

reviewsdf = pd.DataFrame(columns = ['product_name','review','user_rating'])
for link in links:
  driver.get(link)
  title = driver.find_element_by_xpath('//*[@id="content"]/div/div/div[3]/div/div/div[1]/h1').text.replace('\n',' - ')
  print(title)
  #ratings_elems = driver.find_elements_by_xpath('/html/body/div[2]/div/div[2]/div[2]/div[2]/div/div/div[3]/div/div/div[2]/div[8]/div/div[1]/div[2]/span[2]')
  ratings_elems = driver.find_elements_by_xpath('//span[@class="BAscore_norm"]')
  ratings = []
  for rating in ratings_elems:
    ratings.append(float(rating.text))
  #reviews_elems = driver.find_elements_by_xpath('/html/body/div[2]/div/div[2]/div[2]/div[2]/div/div/div[3]/div/div/div[2]/div[8]/div/div/div[2]')
  reviews_elems = driver.find_elements_by_xpath('//*[@id="rating_fullview_content_2"]')
  reviews = []
  for review in reviews_elems:
    lines_list = review.text.split('\n')
    lines_list = lines_list[5:]
    reviews.append((' '.join(lines_list)))
  for review, rating in list(zip(reviews, ratings)):
    reviewsdf.loc[len(reviewsdf)] = [title, review, rating]

reviewsdf.to_csv('beer_data.csv', index = False)

import pandas as pd

beer_data = pd.read_csv(r"training_data (1).csv")
display(beer_data)

"""## Task B

Here we assume that a specific beer customer has specified three attributes that they are interested in: hoppy, fruity, and sweet. To collect all instances of hoppy and fruity, we abbreviate the attributes to 'hop' and 'fruit'. 

We decided on these attributes after conducting a word frequency analysis on the reviews, shown below. Each of the three attributes occured at least 800 times in the collective set of reviews.
"""

import nltk
nltk.download("popular")
from nltk.tokenize import word_tokenize
import string

top_N = 400

a = beer_data['review'].str.cat(sep=' ')
words = nltk.tokenize.word_tokenize(a)
word_dist = nltk.FreqDist(words)

rslt = pd.DataFrame(word_dist.most_common(top_N),
                    columns=['Word', 'Frequency'])

from nltk.corpus import stopwords
stop = stopwords.words('english')

rslt['Word'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
rslt['Word'].str.replace('[{}]'.format(string.punctuation), '')
display(rslt[0:50])

"""## Task C

Next we perform cosine similarity with the attributes specified by 'the customer': hop, fruit, and sweet. This gives us a basic measure of how similar each review is to the desired attributes.
"""

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

def calculate_similarity(attributes_doc, corpus_list, product_list):
  corpus_list.append(attributes_doc)

  # Create the Document Term Matrix
  tfidf_vectorizer = TfidfVectorizer(stop_words='english')
  #tfidf_vectorizer = TfidfVectorizer()
  sparse_matrix = tfidf_vectorizer.fit_transform(corpus_list) # no error up to this point

  doc_term_matrix = sparse_matrix.todense()
  df = pd.DataFrame(doc_term_matrix, 
                    columns=tfidf_vectorizer.get_feature_names()) # no error up to this point

  for i in list(df.columns):
    if df.loc[len(corpus_list)-1,i] == 0:
      df = df.drop(i, axis=1) 

  cosine_result = cosine_similarity(df, df)
  cosine_values_list = []
  for i in range(len(cosine_result)):
    b = cosine_result[i][-1]
    cosine_values_list.append(b)
  
  cosine_values_list = cosine_values_list[:-1]
  similarity_series = pd.Series(cosine_values_list)

  corpus_list.remove(attributes_doc)
  review_series = pd.Series(corpus_list)
  product_series = pd.Series(product_list)

  result_df = pd.concat([product_series, review_series, similarity_series],axis=1)

  result_df.columns = ['product_name', 'review', 'similarity']

  return result_df

sim = calculate_similarity('hop fruit sweet', list(beer_data['review'].values), list(beer_data['product_name'].values))

beer_data['similarity'] = sim.similarity

beer_data.to_csv('beer_data_sim.csv', index = False)

"""## Task D
Now, we conduct feature level sentiment analysis for each of the three features. Our regex expression below pulls 3 words before and after each instance of an attribute being mentioned, and sentiment analysis is then conducted to determine if these mentions are positive or negative.
"""

import re

reviews = beer_data.review

hop = []
for i in reviews:
  chopped = re.findall('[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*hop[a-z]*[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*', i)
  chopped = ' '.join(chopped)
  if chopped == '':
    hop.append(None)
  else: 
    hop.append(chopped)
  
beer_data['hop'] = hop

fruit = []
for i in reviews:
  chopped = re.findall('[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*fruit[a-z]*[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*', i)
  chopped = ' '.join(chopped)
  if chopped == '':
    fruit.append(None)
  else: 
    fruit.append(chopped)
  
beer_data['fruit'] = fruit

sweet = []
for i in reviews:
  chopped = re.findall('[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*sweet[a-z]*[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*[\S+.!?]*\s*', i)
  chopped = ' '.join(chopped)
  if chopped == '':
    sweet.append(None)
  else: 
    sweet.append(chopped)
  
beer_data['sweet'] = sweet

!pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer 
  
# function to print sentiments 
# of the sentence. 
def sentiment_scores(sentence): 
  
    sid_obj = SentimentIntensityAnalyzer() 
    sentiment_dict = sid_obj.polarity_scores(sentence) 
    return sentiment_dict['compound']

hop_text = beer_data.hop
fruit_text = beer_data.fruit
sweet_text = beer_data.sweet

hop_sent= []
for i in hop_text:
  if i == None:
    hop_sent.append(0)
  else:
    hop_sent.append(sentiment_scores(i))

beer_data['hop_sent'] = hop_sent

fruit_sent= []
for i in fruit_text:
  if i == None:
    fruit_sent.append(0)
  else:
    fruit_sent.append(sentiment_scores(i))

beer_data['fruit_sent'] = fruit_sent

sweet_sent= []
for i in sweet_text:
  if i == None:
    sweet_sent.append(0)
  else:
    sweet_sent.append(sentiment_scores(i))

beer_data['sweet_sent'] = sweet_sent

beer_data['average_sent'] = (beer_data.hop_sent + beer_data.fruit_sent + beer_data.sweet_sent)/3
beer_data['elevation_score'] = beer_data.similarity + beer_data.average_sent

"""After calculating the average sentiment for each review given its sentiments surrounding the three attributes, we create a new metric, 'elvation score', to simply sum the cosine similarity and average sentiments for each review (Note that while we are doing this for each review, what we are really interested in is the average elevation score for each beer).

## Task E
Below, we look at the average elevation score (average similarity score + average feature sentiment score) and recommend the beers with the top 3 elevation scores for the attributes hop, fruit, and sweet. The recommended beers are output below:

Double Orange Starfish - Aslin Beer Company

DFPF - J. Wakefield Brewing

Double Dry Hopped All Citra Everything - Other Half Brewing Company
"""

for i in range(3):
  display(beer_data.groupby(['product_name']).mean().sort_values(by = 'elevation_score', ascending = False).index[i])

"""## Task F
Now we evaluate how the recommendation would change if we use word vectors to create a similarity metric as opposed to cosine similarity. We use the spacy package and the en_core_web_md word vector set to get this word vector similarity score for each beer.
"""

!python -m spacy download en_core_web_md

import csv
import pandas as pd
import nltk
import numpy as np
from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from tempfile import NamedTemporaryFile
import shutil
import warnings
import spacy
import en_core_web_md
# nlp = spacy.load('en')

nlp = en_core_web_md.load()

warnings.filterwarnings("ignore", category = DeprecationWarning)

attributes = 'hop fruit sweet'

reviews_df = beer_data.review
reviews_df = reviews_df.to_frame()

reviews_df['similarity'] = -1

for index, row in reviews_df.iterrows():
  reviews_df.loc[index,'similarity'] = nlp(row['review']).similarity(nlp(attributes))

"""We again want to make a metric based on this new similarity score as well as the sentiments for each attribute. Thus, we create another elevation score, this time with the word vector similarity instead of cosine similarity (vector_elevation = vector_similarity + average_sent)."""

beer_data['vector_similarity'] = reviews_df['similarity']
beer_data['vector_elevation'] = beer_data.vector_similarity + beer_data.average_sent

for i in range(3):
  display(beer_data.groupby(['product_name']).mean().sort_values(by = 'vector_elevation', ascending = False).index[i])

"""Interestingly, the vector similarity approach still recommends the Double Dry Hopped All Citra Everything, but also recommends two different beers. 

To compare these recommendations, we can look at one more metric: what % of each beer's reviews mention an attribute specified by the customer (i.e. any of the attributes is mentioned one or more times).
"""

def create_has(attribute1, attribute2, attribute3):
  beer_data['has ' + attribute1] = 0
  beer_data['has ' + attribute2] = 0
  beer_data['has ' + attribute3] = 0
  reviews = list(beer_data['review'].values)

  for review in reviews:
    if attribute1 in review:
      beer_data.loc[reviews.index(review), 'has ' + attribute1] = 1
    else:
      beer_data.loc[reviews.index(review), 'has ' + attribute1] = 0
    if attribute2 in review:
      beer_data.loc[reviews.index(review), 'has ' + attribute2] = 1
    else:
      beer_data.loc[reviews.index(review), 'has ' + attribute2] = 0
    if attribute3 in review:
      beer_data.loc[reviews.index(review), 'has ' + attribute3] = 1
    else:
      beer_data.loc[reviews.index(review), 'has ' + attribute3] = 0
  return beer_data

beer_data = create_has('hop', 'fruit', 'sweet')

def f(row):
  if row['has hop'] + row['has fruit'] + row['has sweet'] == 0:
    val = 0
  else:
    val = 1
  return val

beer_data['contains_attribute'] = beer_data.apply(f, axis = 1)

"""Now we can again look at the top 3 beers for cosine similarity and vector similarity, respectively and compare."""

display(beer_data.groupby(['product_name']).mean().sort_values(by = 'elevation_score', ascending = False)[:3])

display(beer_data.groupby(['product_name']).mean().sort_values(by = 'vector_elevation', ascending = False)[:3])

"""We can see that the cosine similarity approach seems to recommend 3 beers that contain the attributes at a higher rate (88%, 96% and 92%) than the word vector similarity recommendation (88%, 88%, 92%). This makes intuitive sense as the word vector similarity score will be taking into account synonyms in addition to the attributes themselves.

## Task G
Finally, we can check the simple approach of recommending the beers with the highest ratings.
"""

display(beer_data.groupby(['product_name']).mean().sort_values(by = 'user_rating', ascending = False)[:3])

"""From the three beers with the highest ratings shown above, none of them were recommended by the cosine similarity or vector similarity systems. They all have relatively low occurence percentages of the attributes desired, and low elevation scores. Thus, we see the value in a recommendation system that takes attributes and sentiments into account to deliver a recommendation that matches the qualities the customer desires."""